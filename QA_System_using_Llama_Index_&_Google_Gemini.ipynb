{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOREhjI0tcNBJyKOMg0Wz+i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khuzaima2182/Generative-AI/blob/main/QA_System_using_Llama_Index_%26_Google_Gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "fNrXdBs19IxC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8802f2ae-63ec-448d-ad4c-395d46941c8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (from -r requirement.txt (line 1)) (0.12.12)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (from -r requirement.txt (line 2)) (0.8.3)\n",
            "Requirement already satisfied: llama-index-llms-gemini in /usr/local/lib/python3.11/dist-packages (from -r requirement.txt (line 3)) (0.4.4)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (from -r requirement.txt (line 4)) (5.1.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from -r requirement.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.11/dist-packages (from -r requirement.txt (line 6)) (7.34.0)\n",
            "Requirement already satisfied: llama-index-embeddings-gemini in /usr/local/lib/python3.11/dist-packages (from -r requirement.txt (line 7)) (0.3.1)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (from -r requirement.txt (line 8)) (1.41.1)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirement.txt (line 1)) (0.4.2)\n",
            "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirement.txt (line 1)) (0.4.0)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.12 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirement.txt (line 1)) (0.12.12)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirement.txt (line 1)) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirement.txt (line 1)) (0.6.4)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirement.txt (line 1)) (0.3.14)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirement.txt (line 1)) (0.4.2)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirement.txt (line 1)) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirement.txt (line 1)) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirement.txt (line 1)) (0.4.3)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirement.txt (line 1)) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index->-r requirement.txt (line 1)) (3.9.1)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.11/dist-packages (from google-generativeai->-r requirement.txt (line 2)) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai->-r requirement.txt (line 2)) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai->-r requirement.txt (line 2)) (2.155.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai->-r requirement.txt (line 2)) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai->-r requirement.txt (line 2)) (4.25.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai->-r requirement.txt (line 2)) (2.10.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai->-r requirement.txt (line 2)) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai->-r requirement.txt (line 2)) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai->-r requirement.txt (line 2)) (1.25.0)\n",
            "Requirement already satisfied: pillow<11.0.0,>=10.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-gemini->-r requirement.txt (line 3)) (10.4.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from IPython->-r requirement.txt (line 6)) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from IPython->-r requirement.txt (line 6)) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from IPython->-r requirement.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from IPython->-r requirement.txt (line 6)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from IPython->-r requirement.txt (line 6)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from IPython->-r requirement.txt (line 6)) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from IPython->-r requirement.txt (line 6)) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from IPython->-r requirement.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from IPython->-r requirement.txt (line 6)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from IPython->-r requirement.txt (line 6)) (4.9.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirement.txt (line 8)) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirement.txt (line 8)) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirement.txt (line 8)) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirement.txt (line 8)) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirement.txt (line 8)) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirement.txt (line 8)) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirement.txt (line 8)) (2.2.2)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirement.txt (line 8)) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirement.txt (line 8)) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirement.txt (line 8)) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirement.txt (line 8)) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirement.txt (line 8)) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirement.txt (line 8)) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirement.txt (line 8)) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirement.txt (line 8)) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirement.txt (line 8)) (6.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->-r requirement.txt (line 8)) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->-r requirement.txt (line 8)) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->-r requirement.txt (line 8)) (1.21.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirement.txt (line 8)) (4.0.12)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai->-r requirement.txt (line 2)) (1.66.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai->-r requirement.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai->-r requirement.txt (line 2)) (4.9)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->IPython->-r requirement.txt (line 6)) (0.8.4)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index->-r requirement.txt (line 1)) (1.59.6)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (3.11.11)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (1.2.15)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (2024.10.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (0.8.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->-r requirement.txt (line 1)) (0.1.10)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirement.txt (line 1)) (4.12.3)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirement.txt (line 1)) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirement.txt (line 1)) (0.5.20)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index->-r requirement.txt (line 1)) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index->-r requirement.txt (line 1)) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit->-r requirement.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit->-r requirement.txt (line 8)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit->-r requirement.txt (line 8)) (2024.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->IPython->-r requirement.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->-r requirement.txt (line 6)) (0.2.13)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai->-r requirement.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai->-r requirement.txt (line 2)) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit->-r requirement.txt (line 8)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit->-r requirement.txt (line 8)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit->-r requirement.txt (line 8)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit->-r requirement.txt (line 8)) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit->-r requirement.txt (line 8)) (3.0.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai->-r requirement.txt (line 2)) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai->-r requirement.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai->-r requirement.txt (line 2)) (4.1.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (1.18.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirement.txt (line 1)) (2.6)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirement.txt (line 8)) (5.0.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai->-r requirement.txt (line 2)) (1.69.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai->-r requirement.txt (line 2)) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai->-r requirement.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit->-r requirement.txt (line 8)) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirement.txt (line 8)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirement.txt (line 8)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirement.txt (line 8)) (0.22.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (0.14.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->-r requirement.txt (line 8)) (0.1.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index->-r requirement.txt (line 1)) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index->-r requirement.txt (line 1)) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index->-r requirement.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai->-r requirement.txt (line 2)) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit->-r requirement.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.12->llama-index->-r requirement.txt (line 1)) (3.26.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirement.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.gemini import Gemini\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "from llama_index.core import Settings\n",
        "\n",
        "from llama_index.core import StorageContext, load_index_from_storage\n",
        "\n",
        "from llama_index.embeddings.gemini import GeminiEmbedding"
      ],
      "metadata": {
        "id": "n5Fl1H-F8ZgJ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "mHMtknQE8nj5"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_api_key = userdata.get(\"GOOGLE_API_KEY\")"
      ],
      "metadata": {
        "id": "y3-Uv6rC8xnK"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key = google_api_key)\n"
      ],
      "metadata": {
        "id": "zUlDHejJ81bj"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for models in genai.list_models():\n",
        "  if 'generateContent' in models.supported_generation_methods:\n",
        "    print(models.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "jVyn1lhA9BFF",
        "outputId": "d1b0c157-06f4-493e-9a5d-ed5f7add336b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro\n",
            "models/gemini-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-pro-exp-0801\n",
            "models/gemini-1.5-pro-exp-0827\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-exp-0827\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0924\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-exp-1206\n",
            "models/gemini-exp-1121\n",
            "models/gemini-exp-1114\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/learnlm-1.5-pro-experimental\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader('/content/').load_data()"
      ],
      "metadata": {
        "id": "DNTjpXoF9Y9c"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = documents"
      ],
      "metadata": {
        "id": "FnYGM9kSwoHy"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(doc[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vG9V8Q9mw0x9",
        "outputId": "3a9ea232-c1bd-4107-8522-3c0b01e2bdd0"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Introduction to Vertex AI \r\n",
            "\r\n",
            "bookmark_border\r\n",
            "\r\n",
            "Vertex AI is a machine learning (ML) platform that lets you train and deploy ML models and AI applications, and customize large language models (LLMs) for use in your AI-powered applications. Vertex AI combines data engineering, data science, and ML engineering workflows, enabling your teams to collaborate using a common toolset and scale your applications using the benefits of Google Cloud.\r\n",
            "\r\n",
            "Vertex AI provides several options for model training and deployment:\r\n",
            "\r\n",
            "AutoML lets you train tabular, image, text, or video data without writing code or preparing data splits. These models can be deployed for online prediction or queried directly for batch prediction.\r\n",
            "\r\n",
            "Custom training gives you complete control over the training process, including using your preferred ML framework, writing your own training code, and choosing hyperparameter tuning options. You can import your custom-trained model into the Model Registry and deploy it to an endpoint for online prediction using prebuilt or custom containers. Or you can query it directly for batch predictions.\r\n",
            "\r\n",
            "Model Garden lets you discover, test, customize, and deploy Vertex AI and select open-source (OSS) models and assets.\r\n",
            "\r\n",
            "Generative AI gives you access to Google's large generative AI models for multiple modalities (text, code, images, speech). You can tune Google's LLMs to meet your needs, and then deploy them for use in your AI-powered applications.\r\n",
            "\r\n",
            "After you deploy your models, use Vertex AI's end-to-end MLOps tools to automate and scale projects throughout the ML lifecycle. These MLOps tools are run on fully-managed infrastructure that you can customize based on your performance and budget needs.\r\n",
            "\r\n",
            "You can use the Vertex AI SDK for Python to run the entire machine learning workflow in Vertex AI Workbench, a Jupyter notebook-based development environment. You can collaborate with a team to develop your model in Colab Enterprise, a version of Colaboratory that is integrated with Vertex AI. Other available interfaces include the Google Cloud console, the Google Cloud CLI command line tool, client libraries, and Terraform (limited support).\r\n",
            "\r\n",
            "Vertex AI and the machine learning (ML) workflow\r\n",
            "This section provides an overview of the machine learning workflow and how you can use Vertex AI to build and deploy your models.\r\n",
            "\r\n",
            "diagram of ML workflow\r\n",
            "\r\n",
            "Data preparation: After extracting and cleaning your dataset, perform exploratory data analysis (EDA) to understand the data schema and characteristics that are expected by the ML model. Apply data transformations and feature engineering to the model, and split the data into training, validation, and test sets.\r\n",
            "\r\n",
            "Explore and visualize data using Vertex AI Workbench notebooks. Vertex AI Workbench integrates with Cloud Storage and BigQuery to help you access and process your data faster.\r\n",
            "\r\n",
            "For large datasets, use Dataproc Serverless Spark from a Vertex AI Workbench notebook to run Spark workloads without having to manage your own Dataproc clusters.\r\n",
            "\r\n",
            "Model training: Choose a training method to train a model and tune it for performance.\r\n",
            "\r\n",
            "To train a model without writing code, see the AutoML overview. AutoML supports tabular, image, text, and video data.\r\n",
            "\r\n",
            "To write your own training code and train custom models using your preferred ML framework, see the Custom training overview.\r\n",
            "\r\n",
            "Optimize hyperparameters for custom-trained models using custom tuning jobs.\r\n",
            "\r\n",
            "Vertex AI Vizier tunes hyperparameters for you in complex machine learning (ML) models.\r\n",
            "\r\n",
            "Use Vertex AI Experiments to train your model using different ML techniques and compare the results.\r\n",
            "\r\n",
            "Register your trained models in the Vertex AI Model Registry for versioning and hand-off to production. Vertex AI Model Registry integrates with validation and deployment features such as model evaluation and endpoints.\r\n",
            "\r\n",
            "Model evaluation and iteration: Evaluate your trained model, make adjustments to your data based on evaluation metrics, and iterate on your model.\r\n",
            "\r\n",
            "Use model evaluation metrics, such as precision and recall, to evaluate and compare the performance of your models. Create evaluations through Vertex AI Model Registry, or include evaluations in your Vertex AI Pipelines workflow.\r\n",
            "Model serving: Deploy your model to production and get online predictions or query it directly for batch predictions.\r\n",
            "\r\n",
            "Deploy your custom-trained model using prebuilt or custom containers to get real-time online predictions (sometimes called HTTP prediction).\r\n",
            "\r\n",
            "Get asynchronous batch predictions, which don't require deployment to endpoints.\r\n",
            "\r\n",
            "Optimized TensorFlow runtime lets you serve TensorFlow models at a lower cost and with lower latency than open source based prebuilt TTensorFlow serving containers.\r\n",
            "\r\n",
            "For online serving cases with tabular models, use Vertex AI Feature Store to serve features from a central repository and monitor feature health.\r\n",
            "\r\n",
            "Vertex Explainable AI helps you understand how each feature contributes to model prediction (feature attribution) and find mislabeled data from the training dataset (example-based explanation).\r\n",
            "\r\n",
            "Deploy and get online predictions for models trained with BigQuery ML.\r\n",
            "\r\n",
            "Model monitoring: Monitor the performance of your deployed model. Use incoming prediction data to retrain your model for improved performance.\r\n",
            "\r\n",
            "Vertex AI Model Monitoring monitors models for training-serving skew and prediction drift and sends you alerts when the incoming prediction data skews too far from the training baseline.\r\n",
            "What's next\r\n",
            "Learn about Vertex AI's MLOps features.\r\n",
            "\r\n",
            "Learn about interfaces that you can use to interact with Vertex AI.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conversion of data into embedding"
      ],
      "metadata": {
        "id": "07QOf65VxG_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_embed_model = GeminiEmbedding(model_name = \"models/embedding-001\")"
      ],
      "metadata": {
        "id": "5tUwFlckw4zW"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Gemini(models = 'gemini-pro', api_key = google_api_key)"
      ],
      "metadata": {
        "id": "cKgJDZEJxmDr"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Settings in LlamaIndex\n",
        "\n",
        "**The service context container is a utility container for LlamaIndex index and query classes. The container contains the following objects that are commonly used for configuring every index and query, such as the LLM, the PromptHelper (for configuring input size/chunk size), the BaseEmbedding (for configuring the embedding model), and more.**\n",
        "\n",
        "Introduced in v0.10.0, there is a new global Settings object intended to replace the old ServiceContext configuration.\n",
        "\n",
        "The new Settings object is a global settings, with parameters that are lazily instantiated. Attributes like the LLM or embedding model are only loaded when they are actually required by an underlying module.\n",
        "\n",
        "Previously with the service context, various modules often did not use it, and it also forced loading every component into memory at runtime (even if those components weren't used).\n",
        "\n",
        "\n",
        "[Read More](https://docs.llamaindex.ai/en/stable/module_guides/supporting_modules/service_context_migration/)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AH5n-_z8y-cY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "Settings.llm = Gemini(api_key=google_api_key)\n",
        "Settings.embed_model = GeminiEmbedding(model=\"gemini-pro\")\n",
        "Settings.node_parser = SentenceSplitter(chunk_size=800, chunk_overlap=20)"
      ],
      "metadata": {
        "id": "10oID0pwyAXq"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating the Vectors from our data"
      ],
      "metadata": {
        "id": "mB6NV05g2AAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndex.from_documents(\n",
        "    doc, embed_model=Settings.embed_model\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "zT7zkOs6zWDM"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index.storage_context.persist()"
      ],
      "metadata": {
        "id": "Am9vPgPH23LO"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "query_engine = index.as_query_engine(llm=Settings.llm)"
      ],
      "metadata": {
        "id": "giqzkgp9Z0_k"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = query_engine.query(\"What is custom-trained models? How they work?\")\n",
        "print(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "4D3GcLG1aV-o",
        "outputId": "92a257a2-40c3-420b-eaa5-5aef89ecb69f"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom-trained models can be deployed using prebuilt or custom containers to get real-time online predictions.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BTMZNIF_afgk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}